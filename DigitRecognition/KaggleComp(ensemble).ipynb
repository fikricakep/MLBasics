{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder,StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers import Flatten,Dropout\n",
    "from keras.layers import BatchNormalization,Average\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downloading dataset\n",
    "!pip install requests\n",
    "!pip install tqdm\n",
    "import requests\n",
    "!pip install wget\n",
    "import wget\n",
    "url = 'https://storage.googleapis.com/kaggle-competitions-data/kaggle/3004/train.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1541570583&Signature=BEHxUmIlbaz5dBiLA3wj8J%2FdxsL%2BrFmdhPcKMONq0ngFhQu1d1G8577KtGdzvo9dEPlqypIQp3x7w91216gdAYscj2x4MphYWv8vY6J0DzKVeegSIw6ahgM5nrivbC%2BDxV4H4w5eWEDitNR8mQZt8lQKCJF8FcciFkMFCHIIR1oLmI6YUjUwTZMR9ZzCm00Jd7O8wi1GXPP10k1pBY6BfD0sgFP5EKVIUPsn%2BiayA37v9xD7U3CmXaWIUb%2FcLB7281idcyUNQWMSKYQ9f5EtJ2D0P11w7s2nZVTBKhNGD3V9uZNF5LEPbuDtxxQenC3%2B7kxjwELIqEk8ddpc0HUU4Q%3D%3D'  \n",
    "wget.download(url, './')\n",
    "url = 'https://storage.googleapis.com/kaggle-competitions-data/kaggle/3004/test.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1541570649&Signature=DPqXGLD4zVsuTuh4xBHoAD3ZA0wuWCkmakSK2TUPpYAoLwibDIlmGSt3sH4fIfWjRmRG759ekxnjb%2BCUjJOnDhVfS5vi8iZKt3tStgovo4uYopb%2B2%2BCXsrp%2BK9fgYQ4lX1bLN6%2FUUSVsuv%2Fx7AW01OpqCMJ7wQZjyuWqjnGp18bwo0FtroV%2BX8iaa3Ea2vgddZDtYrN0DpZ5%2B6AGaKfxM1aw2ApHU2HC77HuYwyFwN4XuanzUpOc8PA2ri5wsTo5InPrz2DV6wWkwRl2FSR5KMBxKeLp9KfBnM3OamaOlg50DNVVL%2Fo2GYQsmUyFoifr1rD1T5qyNeTICP2R8G6g9g%3D%3D'  \n",
    "wget.download(url, './')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv')\n",
    "X = train.iloc[:,1:785].values\n",
    "Y = train.iloc[:,0:1].values\n",
    "X = X.reshape(42000,28,28,1)\n",
    "onehotencoder = OneHotEncoder(categorical_features=[0])\n",
    "Y = onehotencoder.fit_transform(Y).toarray()\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Conv2D(64,5,5,input_shape = (28,28,1),activation = 'relu'))\n",
    "classifier.add(Conv2D(128,5,5,activation = 'relu'))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Conv2D(256,5,5,activation = 'relu'))\n",
    "classifier.add(Conv2D(256,3,3,activation = 'relu'))\n",
    "classifier.add(Dropout(0.25))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "classifier.add(Conv2D(512,3,3,activation = 'relu'))\n",
    "classifier.add(Dropout(0.3))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Conv2D(512,3,3,activation = 'relu'))\n",
    "classifier.add(Dropout(0.4))\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dense(output_dim = 2000, init = 'uniform' , activation ='relu',input_dim = 784))\n",
    "#classifier.add(Dense(output_dim = 1000, init = 'uniform' , activation ='relu'))\n",
    "classifier.add(Dense(output_dim = 10, init = 'uniform' , activation ='softmax'))\n",
    "\n",
    "#compiling model\n",
    "classifier.compile(optimizer = 'adam',loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.1,patience=1, min_lr=0.000000000001)\n",
    "callbacks_list = [reduce_lr]\n",
    "#fitting cnn to training set\n",
    "classifier.fit_generator(datagen.flow(X, Y, batch_size=300),steps_per_epoch=len(X) / 300,nb_epoch = 40 ,callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier1 = Sequential()\n",
    "classifier1.add(Conv2D(512,3,3,input_shape = (28,28,1),activation = 'relu'))\n",
    "classifier1.add(Conv2D(256,5,5,activation = 'relu'))\n",
    "classifier1.add(Conv2D(128,5,5,activation = 'relu'))\n",
    "classifier1.add(Dropout(0.2))\n",
    "classifier1.add(Conv2D(64,5,5,activation = 'relu'))\n",
    "classifier1.add(Dropout(0.25))\n",
    "classifier1.add(Conv2D(32,7,7,activation = 'relu'))\n",
    "classifier1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "classifier1.add(BatchNormalization())\n",
    "classifier1.add(Dropout(0.3))\n",
    "classifier1.add(Flatten())\n",
    "classifier1.add(Dense(output_dim = 2000, init = 'uniform' , activation ='relu',input_dim = 784))\n",
    "#classifier1.add(Dense(output_dim = 1000, init = 'uniform' , activation ='relu'))\n",
    "classifier1.add(Dense(output_dim = 10, init = 'uniform' , activation ='softmax'))\n",
    "\n",
    "#compiling model\n",
    "classifier1.compile(optimizer = 'adam',loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.1,patience=1, min_lr=0.0000000001)\n",
    "callbacks_list = [reduce_lr]\n",
    "#fitting cnn to training set\n",
    "classifier1.fit_generator(datagen.flow(X,Y, batch_size=300),steps_per_epoch=len(X) / 300, nb_epoch = 40 ,callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10)\n",
    "classifier2 = Sequential()\n",
    "classifier2.add(Conv2D(8,3,3,input_shape = (28,28,1),activation = 'relu'))\n",
    "classifier2.add(Conv2D(16,3,3,activation = 'relu'))\n",
    "classifier2.add(Conv2D(32,3,3,activation = 'relu'))\n",
    "classifier2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "classifier2.add(BatchNormalization())\n",
    "classifier2.add(Conv2D(64,3,3,activation = 'relu'))\n",
    "classifier2.add(Conv2D(128,5,5,activation = 'relu'))\n",
    "classifier2.add(Conv2D(256,3,3,activation = 'relu'))\n",
    "classifier2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "classifier2.add(BatchNormalization())\n",
    "\n",
    "classifier2.add(Dropout(0.25))\n",
    "classifier2.add(Conv2D(512,1,1,activation = 'relu'))\n",
    "classifier2.add(Dropout(0.4))\n",
    "\n",
    "classifier2.add(Flatten())\n",
    "\n",
    "classifier2.add(Dense(output_dim = 2000, init = 'uniform' , activation ='relu',input_dim = 784))\n",
    "classifier2.add(Dense(output_dim = 1000, init = 'uniform' , activation ='relu'))\n",
    "classifier2.add(Dropout(0.50))\n",
    "classifier2.add(BatchNormalization())\n",
    "classifier2.add(Dense(output_dim = 10, init = 'uniform' , activation ='softmax'))\n",
    "#compiling model\n",
    "classifier2.compile(optimizer = 'adam',loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.01,patience=1, min_lr=0.0000000000001)\n",
    "callbacks_list = [reduce_lr]\n",
    "#fitting cnn to training st\n",
    "classifier2.fit_generator(datagen.flow(X,Y, batch_size=300),steps_per_epoch=len(X) / 300, nb_epoch = 40 ,callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), input_shape=(28, 28, 1..., activation=\"relu\")`\n",
      "  \"\"\"\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
      "  \n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  import sys\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  \n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (5, 5), activation=\"relu\")`\n",
      "  if __name__ == '__main__':\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
      "  del sys.path[0]\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=784, units=2000, kernel_initializer=\"uniform\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=10, kernel_initializer=\"uniform\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:24: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:24: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., steps_per_epoch=140.0, callbacks=[<keras.ca..., epochs=40)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "140/140 [==============================] - 23s 164ms/step - loss: 13.5714 - acc: 0.1534\n",
      "Epoch 2/40\n",
      "140/140 [==============================] - 16s 116ms/step - loss: 14.0836 - acc: 0.1262\n",
      "Epoch 3/40\n",
      "140/140 [==============================] - 16s 116ms/step - loss: 14.4412 - acc: 0.1040\n",
      "Epoch 4/40\n",
      "140/140 [==============================] - 16s 117ms/step - loss: 14.4332 - acc: 0.1045\n",
      "Epoch 5/40\n",
      "140/140 [==============================] - 16s 117ms/step - loss: 14.4706 - acc: 0.1022\n",
      "Epoch 6/40\n",
      "133/140 [===========================>..] - ETA: 0s - loss: 14.4596 - acc: 0.1029"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10)\n",
    "classifier3 = Sequential()\n",
    "classifier3.add(Conv2D(8,3,3,input_shape = (28,28,1),activation = 'relu'))\n",
    "classifier3.add(Conv2D(16,3,3,activation = 'relu'))\n",
    "classifier3.add(Conv2D(32,3,3,activation = 'relu'))\n",
    "classifier3.add(Conv2D(64,3,3,activation = 'relu'))\n",
    "classifier3.add(Conv2D(128,5,5,activation = 'relu'))\n",
    "classifier3.add(Conv2D(256,3,3,activation = 'relu'))\n",
    "classifier3.add(BatchNormalization())\n",
    "\n",
    "classifier3.add(Conv2D(512,3,3,activation = 'relu'))\n",
    "\n",
    "classifier3.add(Flatten())\n",
    "\n",
    "classifier3.add(Dense(output_dim = 2000, init = 'uniform' , activation ='relu',input_dim = 784))\n",
    "classifier3.add(Dense(output_dim = 10, init = 'uniform' , activation ='softmax'))\n",
    "#compiling model\n",
    "classifier3.compile(optimizer = 'adam',loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.01,patience=1, min_lr=0.0000000000001)\n",
    "callbacks_list = [reduce_lr]\n",
    "#fitting cnn to training st\n",
    "classifier3.fit_generator(datagen.flow(X,Y, batch_size=200),steps_per_epoch=len(X) / 300, nb_epoch = 40 ,callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('./test.csv')\n",
    "X_test = X_test.iloc[:,:].values\n",
    "X_test = X_test.reshape(28000,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "for i in range(0,28000):\n",
    "    for j in range(0,10):\n",
    "        if(y_pred[i,j]<0.5):\n",
    "            y_pred[i,j]=0\n",
    "        if(y_pred[i,j]>0.5):\n",
    "            y_pred[i,j]=1\n",
    "for i in range(0,28000):\n",
    "    for j in range(0,10):\n",
    "        if(y_pred[i,j]==1):\n",
    "            y_pred[i,0] = j\n",
    "y_pred = np.delete(y_pred,np.s_[1:],axis = 1)\n",
    "y_pred = y_pred.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = classifier1.predict(X_test)\n",
    "for i in range(0,28000):\n",
    "    for j in range(0,10):\n",
    "        if(y_pred1[i,j]<0.5):\n",
    "            y_pred1[i,j]=0\n",
    "        if(y_pred1[i,j]>0.5):\n",
    "            y_pred1[i,j]=1\n",
    "for i in range(0,28000):\n",
    "    for j in range(0,10):\n",
    "        if(y_pred1[i,j]==1):\n",
    "            y_pred1[i,0] = j\n",
    "y_pred1 = np.delete(y_pred1,np.s_[1:],axis = 1)\n",
    "y_pred1 = y_pred1.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = classifier2.predict(X_test)\n",
    "for i in range(0,28000):\n",
    "    for j in range(0,10):\n",
    "        if(y_pred2[i,j]<0.5):\n",
    "            y_pred2[i,j]=0\n",
    "        if(y_pred2[i,j]>0.5):\n",
    "            y_pred2[i,j]=1\n",
    "for i in range(0,28000):\n",
    "    for j in range(0,10):\n",
    "        if(y_pred2[i,j]==1):\n",
    "            y_pred2[i,0] = j\n",
    "y_pred2 = np.delete(y_pred2,np.s_[1:],axis = 1)\n",
    "y_pred2 = y_pred2.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(28000):\n",
    "    outputs = [int(y_pred[i]),int(y_pred1[i]),int(y_pred2[i])]\n",
    "    counter=collections.Counter(outputs)\n",
    "    a = counter.most_common(1)\n",
    "    if(a[0][1]>=2):\n",
    "        y_pred[i] = a[0][0]\n",
    "    else:\n",
    "        y_pred[i] = y_pred1[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(y_pred)\n",
    "data.to_csv('output.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
