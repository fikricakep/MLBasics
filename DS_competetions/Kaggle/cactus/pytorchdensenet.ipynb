{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"/kaggle/input/test\"))\n!pip install efficientnet_pytorch\n!pip install torchsummary\nfrom efficientnet_pytorch import EfficientNet\nimport torchvision\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nimport torchvision.models as models\nfrom torchsummary import summary\nimport torch.optim as optim\nimport copy\nimport os\nimport torch\nfrom tqdm.autonotebook import tqdm\nfrom torch.optim.lr_scheduler import _LRScheduler\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom torch.utils.data import Dataset\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_csv = pd.read_csv('/kaggle/input/train.csv')\ntrain_csv.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport random\nfrom sklearn.utils import shuffle\nfrom tqdm import tqdm_notebook\nimport numpy as np\ndata = pd.read_csv('/kaggle/input/train.csv')\ntrain_path = '/kaggle/input/train/train/'\ntest_path = '/kaggle/input/test/test'\n# quick look at the label stats\nprint(data['label'].value_counts())\n\n\ndef readImage(path):\n    # OpenCV reads the image in bgr format by default\n    bgr_img = cv2.imread(path)\n    # We flip it to rgb for visualization purposes\n    b,g,r = cv2.split(bgr_img)\n    rgb_img = cv2.merge([r,g,b])\n    return rgb_img\n\n\n\n## time to plot\n\n# random sampling\nshuffled_data = shuffle(data)\n\nfig, ax = plt.subplots(2,5, figsize=(20,8))\nfig.suptitle('Histopathologic scans of lymph node sections',fontsize=20)\n# Negatives\nfor i, idx in enumerate(shuffled_data[shuffled_data['label'] == 0]['id'][:5]):\n    path = os.path.join(train_path, idx)\n    ax[0,i].imshow(readImage(path + '.tif'))\n    # Create a Rectangle patch\n    box = patches.Rectangle((32,32),32,32,linewidth=4,edgecolor='b',facecolor='none', linestyle=':', capstyle='round')\n    ax[0,i].add_patch(box)\nax[0,0].set_ylabel('Negative samples', size='large')\n# Positives\nfor i, idx in enumerate(shuffled_data[shuffled_data['label'] == 1]['id'][:5]):\n    path = os.path.join(train_path, idx)\n    ax[1,i].imshow(readImage(path + '.tif'))\n    # Create a Rectangle patch\n    box = patches.Rectangle((32,32),32,32,linewidth=4,edgecolor='r',facecolor='none', linestyle=':', capstyle='round')\n    ax[1,i].add_patch(box)\nax[1,0].set_ylabel('Tumor tissue samples', size='large')\n\n\n\n\n\n\n\n## data augmentation\nimport random\nORIGINAL_SIZE = 96      # original size of the images - do not change\n\n# AUGMENTATION VARIABLES\nCROP_SIZE = 90          # final size after crop\nRANDOM_ROTATION = 3    # range (0-180), 180 allows all rotation variations, 0=no change\nRANDOM_SHIFT = 2        # center crop shift in x and y axes, 0=no change. This cannot be more than (ORIGINAL_SIZE - CROP_SIZE)//2 \nRANDOM_BRIGHTNESS = 7  # range (0-100), 0=no change\nRANDOM_CONTRAST = 5    # range (0-100), 0=no change\nRANDOM_90_DEG_TURN = 1  # 0 or 1= random turn to left or right\n\ndef readCroppedImage(path, augmentations = True):\n    # augmentations parameter is included for counting statistics from images, where we don't want augmentations\n    \n    # OpenCV reads the image in bgr format by default\n    bgr_img = cv2.imread(path)\n    # We flip it to rgb for visualization purposes\n    b,g,r = cv2.split(bgr_img)\n    rgb_img = cv2.merge([r,g,b])\n    \n    if(not augmentations):\n        return rgb_img / 255\n    \n    #random rotation\n    rotation = random.randint(-RANDOM_ROTATION,RANDOM_ROTATION)\n    if(RANDOM_90_DEG_TURN == 1):\n        rotation += random.randint(-1,1) * 90\n    M = cv2.getRotationMatrix2D((48,48),rotation,1)   # the center point is the rotation anchor\n    rgb_img = cv2.warpAffine(rgb_img,M,(96,96))\n    \n    #random x,y-shift\n    x = random.randint(-RANDOM_SHIFT, RANDOM_SHIFT)\n    y = random.randint(-RANDOM_SHIFT, RANDOM_SHIFT)\n    \n    # crop to center and normalize to 0-1 range\n    start_crop = (ORIGINAL_SIZE - CROP_SIZE) // 2\n    end_crop = start_crop + CROP_SIZE\n    rgb_img = rgb_img[(start_crop + x):(end_crop + x), (start_crop + y):(end_crop + y)] / 255\n    \n    # Random flip\n    flip_hor = bool(random.getrandbits(1))\n    flip_ver = bool(random.getrandbits(1))\n    if(flip_hor):\n        rgb_img = rgb_img[:, ::-1]\n    if(flip_ver):\n        rgb_img = rgb_img[::-1, :]\n        \n    # Random brightness\n    br = random.randint(-RANDOM_BRIGHTNESS, RANDOM_BRIGHTNESS) / 100.\n    rgb_img = rgb_img + br\n    \n    # Random contrast\n    cr = 1.0 + random.randint(-RANDOM_CONTRAST, RANDOM_CONTRAST) / 100.\n    rgb_img = rgb_img * cr\n    \n    # clip values to 0-1 range\n    rgb_img = np.clip(rgb_img, 0, 1.0)\n    \n    return rgb_img\n\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(2,5, figsize=(20,8))\nfig.suptitle('Cropped histopathologic scans of lymph node sections',fontsize=20)\n# Negatives\nfor i, idx in enumerate(shuffled_data[shuffled_data['label'] == 0]['id'][:5]):\n    path = os.path.join(train_path, idx)\n    ax[0,i].imshow(readCroppedImage(path + '.tif'))\nax[0,0].set_ylabel('Negative samples', size='large')\n# Positives\nfor i, idx in enumerate(shuffled_data[shuffled_data['label'] == 1]['id'][:5]):\n    path = os.path.join(train_path, idx)\n    ax[1,i].imshow(readCroppedImage(path + '.tif'))\nax[1,0].set_ylabel('Tumor tissue samples', size='large')\n\n\n\n## here comes the main part\n\n\n# As we count the statistics, we can check if there are any completely black or white images\ndark_th = 10 / 255      # If no pixel reaches this threshold, image is considered too dark\nbright_th = 245 / 255   # If no pixel is under this threshold, image is considerd too bright\ntoo_dark_idx = []\ntoo_bright_idx = []\n\nx_tot = np.zeros(3)\nx2_tot = np.zeros(3)\ncounted_ones = 0\nfor i, idx in tqdm_notebook(enumerate(shuffled_data['id']), 'computing statistics...(220025 it total)'):\n    path = os.path.join(train_path, idx)\n    imagearray = readCroppedImage(path + '.tif', augmentations = False).reshape(-1,3)\n    # is this too dark\n    if(imagearray.max() < dark_th):\n        too_dark_idx.append(idx)\n        continue # do not include in statistics\n    # is this too bright\n    if(imagearray.min() > bright_th):\n        too_bright_idx.append(idx)\n        continue # do not include in statistics\n    x_tot += imagearray.mean(axis=0)\n    x2_tot += (imagearray**2).mean(axis=0)\n    counted_ones += 1\n    \nchannel_avr = x_tot/counted_ones\nchannel_std = np.sqrt(x2_tot/counted_ones - channel_avr**2)\nchannel_avr,channel_std\n\nprint('There was {0} extremely dark image'.format(len(too_dark_idx)))\nprint('and {0} extremely bright images'.format(len(too_bright_idx)))\nprint('Dark one:')\nprint(too_dark_idx)\nprint('Bright ones:')\nprint(too_bright_idx)\nfig, ax = plt.subplots(2,6, figsize=(25,9))\nfig.suptitle('Almost completely black or white images',fontsize=20)\n# Too dark\ni = 0\nfor idx in np.asarray(too_dark_idx)[:min(6, len(too_dark_idx))]:\n    lbl = shuffled_data[shuffled_data['id'] == idx]['label'].values[0]\n    path = os.path.join(train_path, idx)\n    ax[0,i].imshow(readCroppedImage(path + '.tif', augmentations = False))\n    ax[0,i].set_title(idx + '\\n label=' + str(lbl), fontsize = 8)\n    i += 1\nax[0,0].set_ylabel('Extremely dark images', size='large')\nfor j in range(min(6, len(too_dark_idx)), 6):\n    ax[0,j].axis('off') # hide axes if there are less than 6\n# Too bright\ni = 0\nfor idx in np.asarray(too_bright_idx)[:min(6, len(too_bright_idx))]:\n    lbl = shuffled_data[shuffled_data['id'] == idx]['label'].values[0]\n    path = os.path.join(train_path, idx)\n    ax[1,i].imshow(readCroppedImage(path + '.tif', augmentations = False))\n    ax[1,i].set_title(idx + '\\n label=' + str(lbl), fontsize = 8)\n    i += 1\nax[1,0].set_ylabel('Extremely bright images', size='large')\nfor j in range(min(6, len(too_bright_idx)), 6):\n    ax[1,j].axis('off') # hide axes if there are less than 6","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = train_csv['has_cactus'].unique()\nencoder = {0:'no cactus',1:'has cactus'}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_df,val_df = train_test_split(train_csv,test_size = 0)\nval_df = val_df.reset_index()\nval_df = val_df.drop(['index'],axis = 1)\ntrain_df = train_df.reset_index()\ntrain_df = train_df.drop(['index'],axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class cactus_dataset(Dataset):\n  def __init__(self,image_dir,train_csv,transform = None):\n    self.img_dir = image_dir\n    self.transform = transform\n    self.id = train_csv.iloc[:,0]\n    self.classes =  train_csv.iloc[:,1]\n  def __len__(self):\n    return len(self.id)\n  def __getitem__(self,idx):\n    img_name = os.path.join(self.img_dir, self.id[idx])\n    image = cv2.imread(img_name)\n    if self.transform:\n        image = self.transform(image)\n    label = self.classes[idx]\n    return image,label\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 4\nimport cv2\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transforms = transforms.Compose([\n                                        transforms.ToPILImage(),\n                                    \n                                        transforms.RandomResizedCrop(224),                                    \n                                        transforms.RandomHorizontalFlip(),\n                                        #transforms.RandomRotation(30),\n                                        transforms.ToTensor(),\n                                        transforms.Normalize([0.485, 0.456, 0.406], \n                                                            [0.229, 0.224, 0.225])])\ntest_transforms = transforms.Compose([\n                                        transforms.ToPILImage(),\n                                        transforms.Resize(256),\n                                          transforms.CenterCrop(224),\n                                        transforms.ToTensor(),\n                                        transforms.Normalize([0.485, 0.456, 0.406], \n                                                            [0.229, 0.224, 0.225])])\n\n#inverse normalization for image plot\ntrain_data = cactus_dataset('/kaggle/input/train/train',train_df,transform = train_transforms)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_data = cactus_dataset('/kaggle/input/train/train',val_df,transform = test_transforms)\ntrain_loader = DataLoader(train_data, batch_size=4,\n                        shuffle=True, num_workers=0)\n\n#val_loader = DataLoader(val_data, batch_size=4,shuffle=True, num_workers=0)\ndataloaders = {'train':train_loader}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from efficientnet_pytorch import EfficientNet\nimport torchvision\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nimport torchvision.models as models\nfrom torchsummary import summary\nimport torch.optim as optim\nimport copy\nimport os\nimport torch\nfrom tqdm.autonotebook import tqdm\n\nimport matplotlib.pyplot as plt\n\nclass classifie(nn.Module):\n    def __init__(self,n_classes,pretrained = True ):\n        super(classifie, self).__init__()\n        self.cnn_arch = models.densenet161(pretrained = True)\n        self.linear = nn.Linear(1000, 2)\n        self.bn = nn.BatchNorm1d(16)\n        self.dropout = nn.Dropout(0.2)\n        self.elu = nn.ELU()\n        self.out = nn.Linear(16, 2)\n    def forward(self, input):\n        out = self.cnn_arch(input)\n        res = self.linear(out)\n        #x = self.bn(self.relu(self.linear1(am)))\n        return res","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nclassifier = classifie(n_classes = 2).to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torchsummary import summary\nsummary(classifier,(3,224,224))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.optim as optim\nimport matplotlib.pyplot as plt\nimport random\nfrom torch.autograd import Variable\nimport numpy as np\nimport torch\nfrom torch import nn\nimport sys\ndef train(model,dataloaders,device,num_epochs,lr,batch_size,patience):\n    phase1 = dataloaders.keys()\n    losses = list()\n    criterion = nn.CrossEntropyLoss()\n    acc = list()\n    for epoch in range(num_epochs):\n        print('Epoch:',epoch)\n        optimizer = optim.Adam(model.parameters(), lr=lr,weight_decay = 1e-6)\n        lr = lr*0.9\n        for phase in phase1:\n            epoch_metrics = {\"loss\": [], \"acc\": []}\n            if phase == ' train':\n                model.train()\n            else:\n                model.eval()\n            for  batch_idx, (data, target) in enumerate(dataloaders[phase]):\n                data, target = Variable(data), Variable(target)\n                data = data.type(torch.FloatTensor).to(device)\n                target = target.type(torch.LongTensor).to(device)\n\n                optimizer.zero_grad()\n                output = model(data)\n                loss = criterion(output, target)\n                target = target.type(torch.LongTensor).to(device)\n\n                acc = 100 * (output.detach().argmax(1) == target).cpu().numpy().mean()\n                epoch_metrics[\"loss\"].append(loss.item())\n                epoch_metrics[\"acc\"].append(acc)\n                if(phase =='train'):\n                    loss.backward()\n                    optimizer.step()\n                sys.stdout.write(\n                \"\\r[Epoch %d/%d] [Batch %d/%d] [Loss: %f (%f), Acc: %.2f%% (%.2f%%)]\"\n                % (\n                    epoch,\n                    num_epochs,\n                    batch_idx,\n                    len(dataloaders[phase]),\n                    loss.item(),\n                    np.mean(epoch_metrics[\"loss\"]),\n                    acc,\n                    np.mean(epoch_metrics[\"acc\"]),\n                    )\n                )\n               \n            epoch_acc = np.mean(epoch_metrics[\"acc\"])\n            epoch_loss = np.mean(epoch_metrics[\"loss\"])\n        print('')  \n        print('{} Accuracy: {}'.format(phase,epoch_acc.item()))\n    return losses,acc\n\ndef train_model(model,dataloaders,encoder,lr_scheduler = None,inv_normalize = None,num_epochs=10,lr=0.0001,batch_size=8,patience = None,classes = None):\n    dataloader_train = {}\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    losses = list()\n    accuracy = list()\n    key = dataloaders.keys()\n    perform_test = False\n    for phase in key:\n        if(phase == 'test'):\n            perform_test = True\n        else:2\n            dataloader_train.update([(phase,dataloaders[phase])])\n    losses,accuracy = train(model,dataloader_train,device,num_epochs,lr,batch_size,patience)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nlr = 0.001\ntrain_model(classifier,dataloaders,encoder,inv_normalize = None,num_epochs=4,lr = lr,batch_size = batch_size,patience = None,classes = classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = 0.0001\ntrain_model(classifier,dataloaders,encoder,inv_normalize = None,num_epochs=4,lr = lr,batch_size = batch_size,patience = None,classes = classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class cactus_dataset_test(Dataset):\n  def __init__(self,image_dir,transform = None):\n    self.img_dir = image_dir\n    self.transform = transform\n    self.id = os.listdir(image_dir)\n  def __len__(self):\n    return len(self.id)\n  def __getitem__(self,idx):\n    img_name = os.path.join(self.img_dir, self.id[idx])\n    image = cv2.imread(img_name)\n    if self.transform:\n      image = self.transform(image)\n    return (self.id[idx],image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test1 = cactus_dataset_test('/kaggle/input/test/test',test_transforms)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_loader = DataLoader(test1, batch_size =32, shuffle = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test(model,dataloader,device,batch_size):\n    running_corrects = 0\n    running_loss=0\n    pred = []\n    id = list()\n    sm = nn.Softmax(dim = 1)\n    criterion = nn.CrossEntropyLoss()\n    for batch_idx, (id_1,data) in enumerate(dataloader):\n        data = Variable(data)\n        data = data.type(torch.FloatTensor).to(device)\n        model.eval()\n        output = model(data)\n        output = sm(output)\n        _, preds = torch.max(output, 1)\n        preds = preds.cpu().numpy()\n        preds = np.reshape(preds,(len(preds),1))\n        \n        for i in range(len(preds)):\n            pred.append(preds[i])\n            id.append(id_1[i])\n    return id,pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.optim as optim\nimport matplotlib.pyplot as plt\nfrom torch.autograd import Variable\nimport numpy as np\nimport torch\nfrom torch import nn\nid,pred = test(classifier,test_loader,'cuda',32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = list()\nfor i in range(len(pred)):\n    a.append(pred[i][0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = np.asarray(a)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = np.reshape(a,(-1,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"b = np.asarray(id)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"b = np.reshape(b,(-1,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = np.concatenate((b,a),axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df = pd.DataFrame(sub)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df.columns = ['id','has_cactus']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df.to_csv(\"/kaggle/working/submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}