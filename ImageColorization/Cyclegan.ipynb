{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_colorization.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "vbmGfr-WtP8c",
        "colab_type": "code",
        "outputId": "e55b2aef-02df-49bd-f76b-dfa3248fe2d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        }
      },
      "cell_type": "code",
      "source": [
        "!pip3 install torch torchvision\n",
        "!pip install torchsummary\n",
        "!pip install pyunpack\n",
        "!pip install patool"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Collecting pillow>=4.1.1 (from torchvision)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/5e/e91792f198bbc5a0d7d3055ad552bc4062942d27eaf75c3e2783cf64eae5/Pillow-5.4.1-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 9.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Installing collected packages: pillow\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-5.4.1\n",
            "\u001b[0;31;1mWARNING: The following packages were previously imported in this runtime:\n",
            "  [PIL]\n",
            "You must restart the runtime in order to use newly installed versions.\u001b[0m\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n",
            "Collecting pyunpack\n",
            "  Downloading https://files.pythonhosted.org/packages/79/dc/44cd41fb99d184ae7c2eac439a52ca624d5ece62b0302c3437fcc4ce3b58/pyunpack-0.1.2.tar.gz\n",
            "Collecting easyprocess (from pyunpack)\n",
            "  Downloading https://files.pythonhosted.org/packages/45/3a/4eecc0c7995a13a64739bbedc0d3691fc574245b7e79cff81905aa0c2b38/EasyProcess-0.2.5.tar.gz\n",
            "Building wheels for collected packages: pyunpack, easyprocess\n",
            "  Running setup.py bdist_wheel for pyunpack ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/af/44/08/60613970881e542c0baad1f2dea5ed8e6716bc573f49197b7e\n",
            "  Running setup.py bdist_wheel for easyprocess ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/41/22/19/af15ef6264c58b625a82641ed7483ad05e258fbd8925505227\n",
            "Successfully built pyunpack easyprocess\n",
            "Installing collected packages: easyprocess, pyunpack\n",
            "Successfully installed easyprocess-0.2.5 pyunpack-0.1.2\n",
            "Collecting patool\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/52243ddff508780dd2d8110964320ab4851134a55ab102285b46e740f76a/patool-1.12-py2.py3-none-any.whl (77kB)\n",
            "\u001b[K    100% |████████████████████████████████| 81kB 3.8MB/s \n",
            "\u001b[?25hInstalling collected packages: patool\n",
            "Successfully installed patool-1.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qU5L1VyEtsSY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "from torchsummary import summary\n",
        "from pyunpack import Archive\n",
        "from torch.autograd import Variable\n",
        "from logging import Logger\n",
        "from skimage.color import rgb2lab, lab2rgb, rgb2gray, xyz2lab\n",
        "from skimage.io import imsave"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NsaXdfNjtupR",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "b6007a65-4a03-4f29-ff0a-3c4ce0c97d1f"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f94aaaa9-5f92-4c69-8eb1-8c707c9e0322\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-f94aaaa9-5f92-4c69-8eb1-8c707c9e0322\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"sanchit2843\",\"key\":\"60f3bf5b207ec03851f344c9a6984da9\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "I_oW5Cc_tyPd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5b29keOqtzhg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "3f37920f-3e2f-473f-9ab5-c4ae8f800113"
      },
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c cifar-10"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading sampleSubmission.csv to /content\n",
            "\r  0% 0.00/3.04M [00:00<?, ?B/s]\n",
            "100% 3.04M/3.04M [00:00<00:00, 99.0MB/s]\n",
            "Downloading test.7z to /content\n",
            "100% 609M/610M [00:06<00:00, 129MB/s]\n",
            "100% 610M/610M [00:06<00:00, 102MB/s]\n",
            "Downloading train.7z to /content\n",
            " 85% 89.0M/105M [00:00<00:00, 77.7MB/s]\n",
            "100% 105M/105M [00:00<00:00, 114MB/s]  \n",
            "Downloading trainLabels.csv to /content\n",
            "  0% 0.00/575k [00:00<?, ?B/s]\n",
            "100% 575k/575k [00:00<00:00, 80.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wlXe_b6quCm5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Archive('train.7z').extractall('.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VjXE2cW1uyOl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "a = os.listdir('/content/train')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jbhrtnG1yab_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_name = os.path.join('/content/train', a[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LXLtoniRyiSe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "a[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F5OJjtz0u1Vt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "class DataLoader(Dataset):\n",
        "  def __init__(self,a,root_dir):\n",
        "    self.a = a\n",
        "    self.root_dir = root_dir\n",
        "  def __len__(self):\n",
        "      return len(a)\n",
        "  def __getitem__(self, idx):\n",
        "      img_name = os.path.join(self.root_dir, a[idx])\n",
        "      target = cv2.imread(img_name)\n",
        "      input_img = cv2.imread(img_name,0)\n",
        "      target = target/255\n",
        "      return input_img,target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UV52Lu_3wD0m",
        "colab_type": "code",
        "outputId": "469f8de0-3e80-4473-a5d4-d7b39cf9e10e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        }
      },
      "cell_type": "code",
      "source": [
        "# input to output\n",
        "class Generator_1(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Generator_1,self).__init__()\n",
        "    self.conv1 = nn.Sequential(\n",
        "                                nn.Conv2d(1,32,kernel_size = 4,stride = 2),\n",
        "                                nn.BatchNorm2d(32),\n",
        "                                nn.LeakyReLU(0.5)\n",
        "                              )\n",
        "    self.conv2 = nn.Sequential(\n",
        "                                nn.Conv2d(32,64,kernel_size = 4,stride = 2),\n",
        "                                nn.BatchNorm2d(64),\n",
        "                                nn.LeakyReLU(0.5)\n",
        "                              )\n",
        "    self.conv3 = nn.Sequential(\n",
        "                                nn.Conv2d(64,128,kernel_size = 3,stride = 1),\n",
        "                                nn.BatchNorm2d(128),\n",
        "                                nn.LeakyReLU(0.5)\n",
        "                              )\n",
        "    #Deconvolution\n",
        "    self.deconv1 = nn.Sequential(\n",
        "                                nn.ConvTranspose2d(128,64,kernel_size = 3,stride = 1),\n",
        "                                nn.BatchNorm2d(64),\n",
        "                                nn.LeakyReLU(0.5)\n",
        "                              )\n",
        "    self.deconv2 = nn.Sequential(\n",
        "                                nn.ConvTranspose2d(64,32,kernel_size = 4,stride = 2),\n",
        "                                nn.BatchNorm2d(32),\n",
        "                                nn.LeakyReLU(0.5)\n",
        "                              )\n",
        "    self.deconv3 = nn.Sequential(\n",
        "                                nn.ConvTranspose2d(32,3,kernel_size = 4,stride = 2),\n",
        "                                nn.BatchNorm2d(3),\n",
        "                                nn.LeakyReLU(0.5)\n",
        "                              )\n",
        "    self.deconv4 = nn.Sequential(\n",
        "                                nn.ConvTranspose2d(3,3,kernel_size = 3,stride = 1),\n",
        "                                nn.BatchNorm2d(3),\n",
        "                              )\n",
        "    \n",
        "  def forward(self,x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.conv3(x)\n",
        "    x = self.deconv1(x)\n",
        "    x = self.deconv2(x)\n",
        "    x = self.deconv3(x)\n",
        "    x = F.tanh(self.deconv4(x))\n",
        "    return x\n",
        "  \n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "G_BC = Generator_1().to(device)\n",
        "summary(G_BC, (1, 32, 32))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 15, 15]             544\n",
            "       BatchNorm2d-2           [-1, 32, 15, 15]              64\n",
            "         LeakyReLU-3           [-1, 32, 15, 15]               0\n",
            "            Conv2d-4             [-1, 64, 6, 6]          32,832\n",
            "       BatchNorm2d-5             [-1, 64, 6, 6]             128\n",
            "         LeakyReLU-6             [-1, 64, 6, 6]               0\n",
            "            Conv2d-7            [-1, 128, 4, 4]          73,856\n",
            "       BatchNorm2d-8            [-1, 128, 4, 4]             256\n",
            "         LeakyReLU-9            [-1, 128, 4, 4]               0\n",
            "  ConvTranspose2d-10             [-1, 64, 6, 6]          73,792\n",
            "      BatchNorm2d-11             [-1, 64, 6, 6]             128\n",
            "        LeakyReLU-12             [-1, 64, 6, 6]               0\n",
            "  ConvTranspose2d-13           [-1, 32, 14, 14]          32,800\n",
            "      BatchNorm2d-14           [-1, 32, 14, 14]              64\n",
            "        LeakyReLU-15           [-1, 32, 14, 14]               0\n",
            "  ConvTranspose2d-16            [-1, 3, 30, 30]           1,539\n",
            "      BatchNorm2d-17            [-1, 3, 30, 30]               6\n",
            "        LeakyReLU-18            [-1, 3, 30, 30]               0\n",
            "  ConvTranspose2d-19            [-1, 3, 32, 32]              84\n",
            "      BatchNorm2d-20            [-1, 3, 32, 32]               6\n",
            "================================================================\n",
            "Total params: 216,099\n",
            "Trainable params: 216,099\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.57\n",
            "Params size (MB): 0.82\n",
            "Estimated Total Size (MB): 1.40\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1320: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "w1Z9u_QJN-Vj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "outputId": "1fc9b5a0-1c72-4699-d9b6-96db52562f17"
      },
      "cell_type": "code",
      "source": [
        "# input to output\n",
        "class Generator_2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Generator_2,self).__init__()\n",
        "    self.conv1 = nn.Sequential(\n",
        "                                nn.Conv2d(3,32,kernel_size = 4,stride = 2),\n",
        "                                nn.BatchNorm2d(32),\n",
        "                                nn.LeakyReLU(0.5)\n",
        "                              )\n",
        "    self.conv2 = nn.Sequential(\n",
        "                                nn.Conv2d(32,64,kernel_size = 4,stride = 2),\n",
        "                                nn.BatchNorm2d(64),\n",
        "                                nn.LeakyReLU(0.5)\n",
        "                              )\n",
        "    self.conv3 = nn.Sequential(\n",
        "                                nn.Conv2d(64,128,kernel_size = 3,stride = 1),\n",
        "                                nn.BatchNorm2d(128),\n",
        "                                nn.LeakyReLU(0.5)\n",
        "                              )\n",
        "    #Deconvolution\n",
        "    self.deconv1 = nn.Sequential(\n",
        "                                nn.ConvTranspose2d(128,64,kernel_size = 3,stride = 1),\n",
        "                                nn.BatchNorm2d(64),\n",
        "                                nn.LeakyReLU(0.5)\n",
        "                              )\n",
        "    self.deconv2 = nn.Sequential(\n",
        "                                nn.ConvTranspose2d(64,32,kernel_size = 4,stride = 2),\n",
        "                                nn.BatchNorm2d(32),\n",
        "                                nn.LeakyReLU(0.5)\n",
        "                              )\n",
        "    self.deconv3 = nn.Sequential(\n",
        "                                nn.ConvTranspose2d(32,1,kernel_size = 4,stride = 2),\n",
        "                                nn.BatchNorm2d(1),\n",
        "                                nn.LeakyReLU(0.5)\n",
        "                              )\n",
        "    self.deconv4 = nn.Sequential(\n",
        "                                nn.ConvTranspose2d(1,1,kernel_size = 3,stride = 1),\n",
        "                                nn.BatchNorm2d(1),\n",
        "                              )\n",
        "    \n",
        "  def forward(self,x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.conv3(x)\n",
        "    x = self.deconv1(x)\n",
        "    x = self.deconv2(x)\n",
        "    x = self.deconv3(x)\n",
        "    x = F.tanh(self.deconv4(x))\n",
        "    return x\n",
        "  \n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "G_CB = Generator_2().to(device)\n",
        "summary(G_CB, (3, 32, 32))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 15, 15]           1,568\n",
            "       BatchNorm2d-2           [-1, 32, 15, 15]              64\n",
            "         LeakyReLU-3           [-1, 32, 15, 15]               0\n",
            "            Conv2d-4             [-1, 64, 6, 6]          32,832\n",
            "       BatchNorm2d-5             [-1, 64, 6, 6]             128\n",
            "         LeakyReLU-6             [-1, 64, 6, 6]               0\n",
            "            Conv2d-7            [-1, 128, 4, 4]          73,856\n",
            "       BatchNorm2d-8            [-1, 128, 4, 4]             256\n",
            "         LeakyReLU-9            [-1, 128, 4, 4]               0\n",
            "  ConvTranspose2d-10             [-1, 64, 6, 6]          73,792\n",
            "      BatchNorm2d-11             [-1, 64, 6, 6]             128\n",
            "        LeakyReLU-12             [-1, 64, 6, 6]               0\n",
            "  ConvTranspose2d-13           [-1, 32, 14, 14]          32,800\n",
            "      BatchNorm2d-14           [-1, 32, 14, 14]              64\n",
            "        LeakyReLU-15           [-1, 32, 14, 14]               0\n",
            "  ConvTranspose2d-16            [-1, 1, 30, 30]             513\n",
            "      BatchNorm2d-17            [-1, 1, 30, 30]               2\n",
            "        LeakyReLU-18            [-1, 1, 30, 30]               0\n",
            "  ConvTranspose2d-19            [-1, 1, 32, 32]              10\n",
            "      BatchNorm2d-20            [-1, 1, 32, 32]               2\n",
            "================================================================\n",
            "Total params: 216,015\n",
            "Trainable params: 216,015\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.50\n",
            "Params size (MB): 0.82\n",
            "Estimated Total Size (MB): 1.33\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1320: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "iASWkhQazlHV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "root_dir = '/content/train'\n",
        "dataset = DataLoader(a,root_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_rsaGbZQn2vR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size = 32, shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SQi5F-INwEim",
        "colab_type": "code",
        "outputId": "3ce97963-192b-4783-a8e9-0c5e586d3cb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        }
      },
      "cell_type": "code",
      "source": [
        "class Discriminator_1(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Discriminator_1,self).__init__()\n",
        "    self.conv1 = nn.Sequential(\n",
        "                                nn.Conv2d(3,32,kernel_size = 4,stride = 2),\n",
        "                                nn.BatchNorm2d(32),\n",
        "                                nn.LeakyReLU(0.5)\n",
        "                              )\n",
        "    self.conv2 = nn.Sequential(\n",
        "                                nn.Conv2d(32,64,kernel_size = 4,stride = 2),\n",
        "                                nn.BatchNorm2d(64),\n",
        "                                nn.LeakyReLU(0.5)\n",
        "                              )\n",
        "    self.conv3 = nn.Sequential(\n",
        "                                nn.Conv2d(64,128,kernel_size = 3,stride = 1),\n",
        "                                nn.BatchNorm2d(128),\n",
        "                                nn.LeakyReLU(0.5)\n",
        "                              )\n",
        "    self.conv4 = nn.Sequential(\n",
        "                                nn.Conv2d(128,256,kernel_size = 3,stride = 1),\n",
        "                                nn.BatchNorm2d(256),\n",
        "                                nn.LeakyReLU(0.5)\n",
        "                              )\n",
        "    self.fc1 = nn.Sequential( \n",
        "                                nn.Linear(1024, 512),\n",
        "                                nn.LeakyReLU(0.2),\n",
        "                                nn.Dropout(0.3)\n",
        "                            )\n",
        "    self.fc2 = nn.Sequential( \n",
        "                                nn.Linear(512, 128),\n",
        "                                nn.LeakyReLU(0.2),\n",
        "                                nn.Dropout(0.3)\n",
        "                            )\n",
        "    self.fc3 = nn.Sequential( \n",
        "                                nn.Linear(128, 1),                             \n",
        "                            )\n",
        "    \n",
        "  def forward(self,x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.conv3(x)\n",
        "    x = self.conv4(x)\n",
        "    x = x.view(-1,1024)\n",
        "    x = self.fc1(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.fc3(x)\n",
        "    x = F.sigmoid(x)\n",
        "    return x\n",
        "D_B = Discriminator_1().to(device)\n",
        "summary(D_B, (3, 32, 32))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 15, 15]           1,568\n",
            "       BatchNorm2d-2           [-1, 32, 15, 15]              64\n",
            "         LeakyReLU-3           [-1, 32, 15, 15]               0\n",
            "            Conv2d-4             [-1, 64, 6, 6]          32,832\n",
            "       BatchNorm2d-5             [-1, 64, 6, 6]             128\n",
            "         LeakyReLU-6             [-1, 64, 6, 6]               0\n",
            "            Conv2d-7            [-1, 128, 4, 4]          73,856\n",
            "       BatchNorm2d-8            [-1, 128, 4, 4]             256\n",
            "         LeakyReLU-9            [-1, 128, 4, 4]               0\n",
            "           Conv2d-10            [-1, 256, 2, 2]         295,168\n",
            "      BatchNorm2d-11            [-1, 256, 2, 2]             512\n",
            "        LeakyReLU-12            [-1, 256, 2, 2]               0\n",
            "           Linear-13                  [-1, 512]         524,800\n",
            "        LeakyReLU-14                  [-1, 512]               0\n",
            "          Dropout-15                  [-1, 512]               0\n",
            "           Linear-16                  [-1, 128]          65,664\n",
            "        LeakyReLU-17                  [-1, 128]               0\n",
            "          Dropout-18                  [-1, 128]               0\n",
            "           Linear-19                    [-1, 1]             129\n",
            "================================================================\n",
            "Total params: 994,977\n",
            "Trainable params: 994,977\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.30\n",
            "Params size (MB): 3.80\n",
            "Estimated Total Size (MB): 4.11\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "LwExaAKmOa78",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "outputId": "06a0823d-df02-42f2-d72d-2062dd13ded7"
      },
      "cell_type": "code",
      "source": [
        "class Discriminator_2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Discriminator_2,self).__init__()\n",
        "    self.conv1 = nn.Sequential(\n",
        "                                nn.Conv2d(1,32,kernel_size = 4,stride = 2),\n",
        "                                nn.BatchNorm2d(32),\n",
        "                                nn.LeakyReLU(0.5)\n",
        "                              )\n",
        "    self.conv2 = nn.Sequential(\n",
        "                                nn.Conv2d(32,64,kernel_size = 4,stride = 2),\n",
        "                                nn.BatchNorm2d(64),\n",
        "                                nn.LeakyReLU(0.5)\n",
        "                              )\n",
        "    self.conv3 = nn.Sequential(\n",
        "                                nn.Conv2d(64,128,kernel_size = 3,stride = 1),\n",
        "                                nn.BatchNorm2d(128),\n",
        "                                nn.LeakyReLU(0.5)\n",
        "                              )\n",
        "    self.conv4 = nn.Sequential(\n",
        "                                nn.Conv2d(128,256,kernel_size = 3,stride = 1),\n",
        "                                nn.BatchNorm2d(256),\n",
        "                                nn.LeakyReLU(0.5)\n",
        "                              )\n",
        "    self.fc1 = nn.Sequential( \n",
        "                                nn.Linear(1024, 512),\n",
        "                                nn.LeakyReLU(0.2),\n",
        "                                nn.Dropout(0.3)\n",
        "                            )\n",
        "    self.fc2 = nn.Sequential( \n",
        "                                nn.Linear(512, 128),\n",
        "                                nn.LeakyReLU(0.2),\n",
        "                                nn.Dropout(0.3)\n",
        "                            )\n",
        "    self.fc3 = nn.Sequential( \n",
        "                                nn.Linear(128, 1),                             \n",
        "                            )\n",
        "    \n",
        "  def forward(self,x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.conv3(x)\n",
        "    x = self.conv4(x)\n",
        "    x = x.view(-1,1024)\n",
        "    x = self.fc1(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.fc3(x)\n",
        "    x = F.sigmoid(x)\n",
        "    return x\n",
        "D_C = Discriminator_2().to(device)\n",
        "summary(D_C, (1, 32, 32))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 15, 15]             544\n",
            "       BatchNorm2d-2           [-1, 32, 15, 15]              64\n",
            "         LeakyReLU-3           [-1, 32, 15, 15]               0\n",
            "            Conv2d-4             [-1, 64, 6, 6]          32,832\n",
            "       BatchNorm2d-5             [-1, 64, 6, 6]             128\n",
            "         LeakyReLU-6             [-1, 64, 6, 6]               0\n",
            "            Conv2d-7            [-1, 128, 4, 4]          73,856\n",
            "       BatchNorm2d-8            [-1, 128, 4, 4]             256\n",
            "         LeakyReLU-9            [-1, 128, 4, 4]               0\n",
            "           Conv2d-10            [-1, 256, 2, 2]         295,168\n",
            "      BatchNorm2d-11            [-1, 256, 2, 2]             512\n",
            "        LeakyReLU-12            [-1, 256, 2, 2]               0\n",
            "           Linear-13                  [-1, 512]         524,800\n",
            "        LeakyReLU-14                  [-1, 512]               0\n",
            "          Dropout-15                  [-1, 512]               0\n",
            "           Linear-16                  [-1, 128]          65,664\n",
            "        LeakyReLU-17                  [-1, 128]               0\n",
            "          Dropout-18                  [-1, 128]               0\n",
            "           Linear-19                    [-1, 1]             129\n",
            "================================================================\n",
            "Total params: 993,953\n",
            "Trainable params: 993,953\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.30\n",
            "Params size (MB): 3.79\n",
            "Estimated Total Size (MB): 4.10\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "6yYV7yonwJA1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "d_B_optimizer = optim.Adam(D_B.parameters(), lr=0.000001)\n",
        "d_C_optimizer = optim.Adam(D_C.parameters(), lr=0.000001)\n",
        "g_BC_optimizer = optim.Adam(G_BC.parameters(), lr=0.01)\n",
        "g_CB_optimizer = optim.Adam(G_CB.parameters(), lr=0.01)\n",
        "\n",
        "criterion_GAN = torch.nn.MSELoss()\n",
        "criterion_cycle = torch.nn.L1Loss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ngo0hNUozOqL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def ones_target(size):\n",
        "    '''\n",
        "    Tensor containing ones, with shape = size\n",
        "    '''\n",
        "    data = Variable(torch.ones(size, 1))\n",
        "    data = data.type(torch.cuda.FloatTensor)\n",
        "    return data\n",
        "\n",
        "def zeros_target(size):\n",
        "    '''\n",
        "    Tensor containing zeros, with shape = size\n",
        "    '''\n",
        "    data = Variable(torch.zeros(size, 1))\n",
        "    data = data.type(torch.cuda.FloatTensor)\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MWGEXI4SwO-N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''def train_discriminator(real,fake,optimizer):\n",
        "  optimizer.zero_grad()\n",
        "  N = real.size(0)\n",
        "  #real_data\n",
        "  prediction_real = discriminator(real)\n",
        "  error_real = loss(prediction_real, zeros_target(N))\n",
        "  error_real.backward()\n",
        "  #fake_data\n",
        "  prediction_fake = discriminator(fake)\n",
        "  error_fake = loss(prediction_fake,ones_target(N))\n",
        "  error_fake.backward()\n",
        "  optimizer.step()\n",
        "  return (error_real + error_fake)/2, prediction_real, prediction_fake'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E2hqCyxkzXMH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''def train_generator(optimizer, fake , real_data):\n",
        "    optimizer.zero_grad()\n",
        "    N = fake.size(0)\n",
        "    error2 = loss1(real_data,fake)\n",
        "    error2.backward()\n",
        "    optimizer.step()\n",
        "    error=1\n",
        "    # Sample noise and generate fake data\n",
        "    #prediction = discriminator(fake_data)\n",
        "    #error = loss(prediction, zeros_target(N))\n",
        "    #error.backward()\n",
        "    #optimizer.step()\n",
        "\n",
        "    return error,error2'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BtLSzTu0J3Sl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir generated"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DPZYKAp8z9nx",
        "colab_type": "code",
        "outputId": "22839cea-4329-42c5-9f3f-cd651bfcdd5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1675
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from IPython.display import Image\n",
        "torch.backends.cudnn.benchmark=True\n",
        "for epoch in range(100):\n",
        "  for n_batch,(input_img,output_img) in enumerate(dataloader):\n",
        "        N = input_img.size(0)\n",
        "        #loss for generator B-->C\n",
        "        input_img = input_img.view(N,1,32,32)\n",
        "        input_img = input_img.to(device)\n",
        "        input_img = input_img.type(torch.cuda.FloatTensor)\n",
        "        output_img = output_img.view(N,3,32,32)\n",
        "        output_img = output_img.to(device)\n",
        "        output_img = output_img.type(torch.cuda.FloatTensor)\n",
        "        g_BC_optimizer.zero_grad()\n",
        "        g_CB_optimizer.zero_grad()\n",
        "        \n",
        "        G_BC.train()\n",
        "        fake_data_BC = G_BC(input_img).detach()\n",
        "        loss_bc = criterion_GAN(fake_data_BC,output_img)\n",
        "        #loss for generator C --> B\n",
        "        \n",
        "        G_CB.train()\n",
        "        fake_data_CB = G_CB(output_img).detach()\n",
        "        loss_cb = criterion_GAN(fake_data_CB,input_img)\n",
        "        loss_gan = (loss_bc+loss_cb)/2\n",
        "        \n",
        "        #Cycle loss\n",
        "        \n",
        "        recovered_B = G_CB(fake_data_BC)\n",
        "        loss_cycle_B = criterion_cycle(recovered_B , input_img)\n",
        "        recovered_C = G_BC(fake_data_CB)\n",
        "        loss_cycle_C = criterion_cycle(recovered_C , output_img)\n",
        "        loss_cycle = (loss_cycle_B + loss_cycle_C)/2\n",
        "        \n",
        "        # total loss gan\n",
        "        loss_g = loss_gan + 5*loss_cycle\n",
        "        \n",
        "        # Train generator\n",
        "        loss_g.backward()\n",
        "        g_BC_optimizer.step()\n",
        "        g_CB_optimizer.step()\n",
        "        \n",
        "        if(n_batch%100 == 0):\n",
        "          # train Discriminator B --> C\n",
        "          d_B_optimizer.zero_grad()\n",
        "          real_image = D_B(output_img)\n",
        "          loss_real = criterion_GAN(real_image , zeros_target(N))\n",
        "\n",
        "          fake_image = D_B(fake_data_BC)\n",
        "          loss_fake = criterion_GAN(fake_image , ones_target(N))\n",
        "          loss_B = (loss_real + loss_fake) / 2\n",
        "          loss_B.backward()\n",
        "          d_B_optimizer.step()\n",
        "\n",
        "\n",
        "          # Train Discriminator C --> B\n",
        "\n",
        "          d_C_optimizer.zero_grad()\n",
        "          real_image = D_C(input_img)\n",
        "          loss_real = criterion_GAN(real_image , zeros_target(N))\n",
        "          fake_image = D_C(fake_data_CB)\n",
        "          loss_fake = criterion_GAN(fake_image , ones_target(N))\n",
        "          loss_C = (loss_real + loss_fake) / 2\n",
        "          loss_C.backward()\n",
        "          d_C_optimizer.step()\n",
        "\n",
        "        \n",
        "        # Display Progress every few batches\n",
        "        if(n_batch%600==0):\n",
        "          print('epochs : {}'.format(epoch) ,  'g_error : {}'.format(loss_g) , 'd_error : {}'.format(loss_B))\n",
        "        \n",
        "  torch.optim.lr_scheduler.StepLR(g_optimizer, 2, gamma=0.1, last_epoch=-1)\n",
        "  G_BC.eval()\n",
        "  image,_ = dataset[4]\n",
        "  image = image.reshape((32,32,1))\n",
        "  image = torch.from_numpy(image)\n",
        "  image = image.type(torch.cuda.FloatTensor)\n",
        "  image = image.view(1,1,32,32)\n",
        "  target = G_BC(image).detach()\n",
        "  b = target.to(torch.device(\"cpu\"))\n",
        "  b = b.numpy()\n",
        "  b = np.reshape(b,(32,32,3))\n",
        "  b = b*255\n",
        "  cv2.imwrite('/content/generated/{}.png'.format(epoch),b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1320: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epochs : 0 g_error : 10001.072265625 d_error : 0.2505524158477783\n",
            "epochs : 0 g_error : 9299.5244140625 d_error : 0.24899007380008698\n",
            "epochs : 0 g_error : 9211.935546875 d_error : 0.24729476869106293\n",
            "epochs : 1 g_error : 10358.6298828125 d_error : 0.24622982740402222\n",
            "epochs : 1 g_error : 9831.3193359375 d_error : 0.2507566809654236\n",
            "epochs : 1 g_error : 9831.072265625 d_error : 0.248005211353302\n",
            "epochs : 2 g_error : 8413.3447265625 d_error : 0.251693993806839\n",
            "epochs : 2 g_error : 9197.921875 d_error : 0.24900028109550476\n",
            "epochs : 2 g_error : 9622.6806640625 d_error : 0.24772875010967255\n",
            "epochs : 3 g_error : 10148.517578125 d_error : 0.2516041100025177\n",
            "epochs : 3 g_error : 10024.978515625 d_error : 0.249679297208786\n",
            "epochs : 3 g_error : 9553.8232421875 d_error : 0.2515483796596527\n",
            "epochs : 4 g_error : 9127.287109375 d_error : 0.251237690448761\n",
            "epochs : 4 g_error : 8449.4814453125 d_error : 0.2509765625\n",
            "epochs : 4 g_error : 8722.060546875 d_error : 0.2497122883796692\n",
            "epochs : 5 g_error : 8888.8359375 d_error : 0.2542857229709625\n",
            "epochs : 5 g_error : 9601.1220703125 d_error : 0.2507041394710541\n",
            "epochs : 5 g_error : 8594.05078125 d_error : 0.25021302700042725\n",
            "epochs : 6 g_error : 11431.6103515625 d_error : 0.2507948875427246\n",
            "epochs : 6 g_error : 8966.90234375 d_error : 0.2514912486076355\n",
            "epochs : 6 g_error : 9466.431640625 d_error : 0.2495710849761963\n",
            "epochs : 7 g_error : 9355.7197265625 d_error : 0.2498055398464203\n",
            "epochs : 7 g_error : 9783.8759765625 d_error : 0.24969831109046936\n",
            "epochs : 7 g_error : 7983.595703125 d_error : 0.25037553906440735\n",
            "epochs : 8 g_error : 8650.330078125 d_error : 0.25121453404426575\n",
            "epochs : 8 g_error : 10038.09765625 d_error : 0.24649062752723694\n",
            "epochs : 8 g_error : 8826.4833984375 d_error : 0.2451162189245224\n",
            "epochs : 9 g_error : 8706.013671875 d_error : 0.24750341475009918\n",
            "epochs : 9 g_error : 9538.3896484375 d_error : 0.2489999532699585\n",
            "epochs : 9 g_error : 9283.5673828125 d_error : 0.2472003996372223\n",
            "epochs : 10 g_error : 10331.4453125 d_error : 0.24495074152946472\n",
            "epochs : 10 g_error : 8596.640625 d_error : 0.24678227305412292\n",
            "epochs : 10 g_error : 9714.853515625 d_error : 0.2471533864736557\n",
            "epochs : 11 g_error : 10276.2041015625 d_error : 0.24500712752342224\n",
            "epochs : 11 g_error : 10515.2421875 d_error : 0.247951477766037\n",
            "epochs : 11 g_error : 9135.787109375 d_error : 0.2535598874092102\n",
            "epochs : 12 g_error : 7803.36181640625 d_error : 0.24776017665863037\n",
            "epochs : 12 g_error : 8766.677734375 d_error : 0.24541215598583221\n",
            "epochs : 12 g_error : 9614.6318359375 d_error : 0.2500637173652649\n",
            "epochs : 13 g_error : 9888.4345703125 d_error : 0.24833327531814575\n",
            "epochs : 13 g_error : 9494.763671875 d_error : 0.2466156929731369\n",
            "epochs : 13 g_error : 8593.3232421875 d_error : 0.24604222178459167\n",
            "epochs : 14 g_error : 10103.15234375 d_error : 0.2504352331161499\n",
            "epochs : 14 g_error : 9051.72265625 d_error : 0.2430315762758255\n",
            "epochs : 14 g_error : 8540.1064453125 d_error : 0.24728380143642426\n",
            "epochs : 15 g_error : 9708.271484375 d_error : 0.24549472332000732\n",
            "epochs : 15 g_error : 9816.6953125 d_error : 0.24660103023052216\n",
            "epochs : 15 g_error : 9488.19921875 d_error : 0.2447020262479782\n",
            "epochs : 16 g_error : 10020.056640625 d_error : 0.24320125579833984\n",
            "epochs : 16 g_error : 8585.8017578125 d_error : 0.24486711621284485\n",
            "epochs : 16 g_error : 9521.587890625 d_error : 0.24509400129318237\n",
            "epochs : 17 g_error : 10014.6728515625 d_error : 0.24124331772327423\n",
            "epochs : 17 g_error : 9791.4296875 d_error : 0.2431214600801468\n",
            "epochs : 17 g_error : 8341.9931640625 d_error : 0.2428368479013443\n",
            "epochs : 18 g_error : 8587.90234375 d_error : 0.24172568321228027\n",
            "epochs : 18 g_error : 9901.9501953125 d_error : 0.24172601103782654\n",
            "epochs : 18 g_error : 9686.0771484375 d_error : 0.23818260431289673\n",
            "epochs : 19 g_error : 9740.4296875 d_error : 0.24103300273418427\n",
            "epochs : 19 g_error : 9607.3798828125 d_error : 0.23798254132270813\n",
            "epochs : 19 g_error : 9739.9501953125 d_error : 0.23746255040168762\n",
            "epochs : 20 g_error : 10253.3046875 d_error : 0.23604196310043335\n",
            "epochs : 20 g_error : 10734.44921875 d_error : 0.23812201619148254\n",
            "epochs : 20 g_error : 8274.14453125 d_error : 0.2385985553264618\n",
            "epochs : 21 g_error : 9187.5048828125 d_error : 0.2355370819568634\n",
            "epochs : 21 g_error : 9263.333984375 d_error : 0.23458868265151978\n",
            "epochs : 21 g_error : 9446.7080078125 d_error : 0.23332083225250244\n",
            "epochs : 22 g_error : 7836.3955078125 d_error : 0.23032218217849731\n",
            "epochs : 22 g_error : 9489.677734375 d_error : 0.2295331358909607\n",
            "epochs : 22 g_error : 9932.013671875 d_error : 0.2330491840839386\n",
            "epochs : 23 g_error : 9635.8857421875 d_error : 0.23033347725868225\n",
            "epochs : 23 g_error : 9159.1884765625 d_error : 0.22561228275299072\n",
            "epochs : 23 g_error : 9557.802734375 d_error : 0.22591876983642578\n",
            "epochs : 24 g_error : 8603.716796875 d_error : 0.2252528965473175\n",
            "epochs : 24 g_error : 8792.66796875 d_error : 0.22529764473438263\n",
            "epochs : 24 g_error : 9568.05078125 d_error : 0.22664570808410645\n",
            "epochs : 25 g_error : 9527.7431640625 d_error : 0.22354388236999512\n",
            "epochs : 25 g_error : 11052.9638671875 d_error : 0.22551880776882172\n",
            "epochs : 25 g_error : 10061.6455078125 d_error : 0.2200901359319687\n",
            "epochs : 26 g_error : 10483.935546875 d_error : 0.22135962545871735\n",
            "epochs : 26 g_error : 8983.6826171875 d_error : 0.21755969524383545\n",
            "epochs : 26 g_error : 8780.9208984375 d_error : 0.21842429041862488\n",
            "epochs : 27 g_error : 8939.1181640625 d_error : 0.21200156211853027\n",
            "epochs : 27 g_error : 9888.6611328125 d_error : 0.22004587948322296\n",
            "epochs : 27 g_error : 9055.12890625 d_error : 0.2188931405544281\n",
            "epochs : 28 g_error : 9802.14453125 d_error : 0.21547332406044006\n",
            "epochs : 28 g_error : 9779.203125 d_error : 0.21687957644462585\n",
            "epochs : 28 g_error : 8640.3837890625 d_error : 0.2116421014070511\n",
            "epochs : 29 g_error : 10163.6064453125 d_error : 0.21370698511600494\n",
            "epochs : 29 g_error : 9337.3203125 d_error : 0.2117094099521637\n",
            "epochs : 29 g_error : 10130.44140625 d_error : 0.2069394290447235\n",
            "epochs : 30 g_error : 9693.8671875 d_error : 0.20871701836585999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KlQfk679VYDf",
        "colab_type": "code",
        "outputId": "ca1ba330-2ac0-468e-ec8d-900a42ea5b22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "_,target = dataset[4]\n",
        "\n",
        "c = cv2.imread('/content/generated/34.png')\n",
        "plt.imshow(c)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f1c0dc120b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3VtsVNfd9/HfHhsXnMMDBewnXKRP\nFBEFleQiUqpCRBIOSgVS1SQXJfVLUNuUkIcXyiFgO5wJCQdzSBPytBwaePqE9sWvuIrUSKA0rZRW\nxhVcRAJFIulFSnmJw0lpUjDBM/u9oLX32LO8f/YMY7v9fq4828trrVmz5++Zvf9rrSiO41gAgF5l\nBroDADAUECwBwECwBAADwRIADARLADAQLAHAUFmORtZtXd/j2IIfLtBP9/+08/GIyqxVV0dFepdz\ncfr/gMhqTYoKFHx2znztPbinj7V5LXp5XMb/uFyu4OH5c+dpz//s63xcOSJ9PCtzRq/i0j2/qEA2\n2/frntF//+qNZKmStafCQ9VDFKXXFhc4YX5Q90Md+NX+zscd181sPedlNp5hZD7BQqXmz5mnPQe7\nzpdCr02PemKvPSdrMQ6cx/n19Cyz4AcL9dMDr+cfjNJjzIYVm4K/63ew3LRpk95//31FUaSVK1fq\n/vvv79Pf146t6W/TA65mDH0vt7Gjxw50F/ptKPd9qJ4vtWNrS15nv4LlH//4R3388cdqbm7Wn/70\nJ61cuVLNzc2l7hsADBr9umbZ0tKiGTNmSJLuvvtuffbZZ/riiy9K2jEAGEyi/kx3XLNmjR555JHO\ngFlXV6eXX35Zd911V8Hybec/HdJfuwGgJDd40uJt8kbOP2xoWJ9342co3eBZvWSNXvrJxj7WNjhu\n8KxZtkobd77c+Xio3OBZsahR23ZtSZYqWXs3+wZP/aIGNe3a2vl4KN3gWbNklTb+pOt8GSo3eDbU\nb9S6pjX5B4u8wdOvr+E1NTW6cOFC5+NPP/1UY8cO3YvYAJCmX8HyoYce0pEjRyRJp06dUk1NjW69\n9daSdgwABpN+fQ1/4IEH9PWvf11PPfWUoijSunXrSt0vABhU+n3Ncvny5XbZrApfK0ge/9t17zpH\nlEu/7mBdozGvsUWZwh++Ozq6rrcUuq5ZoEGrPe9anHGdKheuJ852/S53LX2srlldcq8CG9egAmPQ\nnnzpY+8ad2kZ19gCZdo7rnf+3JH1vtA553HGuZxsnnuhS9PXO5L9MF4/5xr3jZKlqStw7mWz3Y73\n8p5wMN0RAAwESwAwECwBwECwBAADwRIADARLADAQLAHAQLAEAAPBEgAMZdlWoiMwxSV5PNM92z7A\nmY1gLA6jyP03kS1c2fXE8YzTYCn/LznTNnoZp+uJWRjZjvR+OZNzInNGjTWbJNDg9cQsryhyV7Yx\nCpkTO7yqCpfqSJwv7qo8xiI5yhkzXHLW+Rkeq2TfnVWH3FUfnVFw6go9vY7uY9PnxSjz8ckSAAwE\nSwAwECwBwECwBAADwRIADARLADAQLAHAQLAEAENZktJz2cLpp8njOXf7cmdpeCcp3Wyv0DabUv5S\n+5Gzr4SZGOzUFTlL7feStN2R2F40cjKynT6ZL18x6codxraoPdpzEs7drXCt3jtJ6aXbgsObMeC1\nFtrCIZvoe3HTIfJZCe5ORYFh6h523Pd8CJ8sAcBAsAQAA8ESAAwESwAwECwBwECwBAADwRIADARL\nADCUJSk9G0iczTvuJFqrhDm4dn5qIFE3keDqtGcnxForgKe3mOmlTC65Kr2xarczD8DNfC7mteno\nSD5yM8mdzwN9T3YPS09Kd8ZcMlccN2YD+Kd64FzPJZPSnZXLzfdyqcqEkum7Hbd3RwjgkyUAGAiW\nAGAgWAKAgWAJAAaCJQAYCJYAYCBYAoCBYAkABoIlABjKMoMnzhbOsI/7uFz9jYLGjAWrMnet/cKH\nc9m+VuXOEinNNg8Vvfwum1hvP3bHIUVparkhNFJ5MzLMrRkia9xLN3ssNMMlbwaPe7ZbxYrbKiGv\npsDzy5utZry5cvbzK03fQzOdum9VY23H0ot+BcvW1lYtXrxY48ePlyTdc889WrNmTVEdAYDBrN+f\nLL/xjW/otddeK2VfAGDQ4polABii2FraJF9ra6s2bNigO++8U5999pkWLlyohx56KFj+3KdtuqOm\ntqiOAsBA6lewbGtr04kTJzRz5kydOXNGc+fO1dGjR1VVVVWw/LKNq3sc27nmpbzjztJPf+9yehHr\n4n//b/C8su5FLd2wNlFVKW9v3NwbPNvXrNPyjRs6H5fuBk/plmgrdEtmx5o1en7jxq4D7op3Jdzp\nur83eHauWa9lG9dbbXSrrFSFvOYKPL9X1mzQ0o3rOh97e30P/A2en6x/WUvWr8o7FhnLH76ybnPw\nd/36Gl5bW6tZs2YpiiLdeeedGjNmjNra2vpTFQAMCf0Klm+99ZbeeOMNSdL58+d18eJF1dbyNRvA\nP69+3Q2fNm2ali9frt/85je6fv261q9fH/wKDgD/DPoVLG+99Vbt3r3bLh/ISc87bu+6UKrrHO51\nqsCFqo5EgmvGuZblJlEb2wR4WwmE20v2PTL2jLC2Ekgt4RcMvcTZjn4kdhvcS87FzHXIJS+X2dsu\nGOWc08V+cUKTR7o6b26IUd5SgU7luh2PepupYSB1CAAMBEsAMBAsAcBAsAQAA8ESAAwESwAwECwB\nwECwBABDeVZK754dWuB491WNw5WlZ9g6iyfYC0gE+pXse9aqy03BTf//5Sxa0VstuWRyt7G4QLkX\ndAivTp/oa5nXLnGFE+oTzTkTD3qpq+/sGR8FD2f7usK4+fwcTk2h93v3pP5iJ7TwyRIADARLADAQ\nLAHAQLAEAAPBEgAMBEsAMBAsAcBAsAQAA8ESAAzlmcETSJxPHndn8MTGhBNrQoadzV+4tlxiVoO1\n7YLdXPoTjOP0/3G5XvrUkZgJE0XpdTm7JUfmthneZKfATJJ+zOCJjD0V/K4bdQVO0Fxixpe3Pa+p\niPHsIROYCZP4e+v9Z34E87e/TmvQm8HjbYkRxidLADAQLAHAQLAEAAPBEgAMBEsAMBAsAcBAsAQA\nA8ESAAxlSUoP5p4mj7sZo8YS91ayq5mJHKorP8k4vS57ZX6nW05lvTy/XGKLg0yFMZ5OUrM7qcBI\nEg+VyGvCba9EZSQp4yS4h473JyPaeI5xCbdwCG/nkSzjvP+KbLCvRQLncPeJLs4OKr3hkyUAGAiW\nAGAgWAKAgWAJAAaCJQAYCJYAYCBYAoCBYAkAhrIkpWcCMTl5POsm1xqJwV6ua7HJvF39sBPODVby\nslEm01uZvCRjYzwDK2gnxW6SfxGvTXJ1enel9JKtxi0pzsvODpTJFC6TjbtmAgwfPdZqb3jWWDXf\n+rhjDlagrlu/OrqrJuMEdVanl8wdBop4/W7/t9F5j6Mi10q3hvr06dOaMWOGDh48KEk6d+6cnn76\nadXV1Wnx4sX68ssvi+oEAAx2qcHyypUr2rhxoyZNmtR57LXXXlNdXZ1+9atf6Wtf+5oOHz58UzsJ\nAAMtNVhWVVVp3759qqmp6TzW2tqq6dOnS5KmTp2qlpaWm9dDABgEUq9ZVlZWqrIyv9jVq1dVVVUl\nSRo9erTOnz9/c3oHAINEFFtLyki7du3SqFGjNGfOHE2aNKnz0+THH3+shoYGHTp0KPi359radEdt\nbWl6DAADoF93w6urq9Xe3q7hw4erra0t7yt6IVv+a1ePY6+++JIWr13d+fh6nH6nUZLiXInuhtv7\nhve0e/NmPffCC4m6+l1VD9Zd5Vz6fblMYJx279io555f01UuY+wb3uut9X8Ucu+A9q/U7qaNeq6+\nq9/+3fDScRI2Ct0N37Nlk+Y3rux8PJTuhjctX6b67Tu7ahoid8O3LF+hxu3butWV3vfNyxuCv+tX\nnuXkyZN15MgRSdLRo0c1ZcqU/lQDAENG6ifLkydPauvWrTp79qwqKyt15MgRbd++XY2NjWpubta4\nceP0+OOPl6OvADBgUoPlxIkT9eabb/Y4fuDAgZvSIQAYjMoyg2f4qJGpx0d0mNcsjSsHVp5+kRez\nbhv11cQjY7sBtz3jmqzz/KJs+KW9ZdSYrgfG9chitlPowbneGmju9pGJa33mZTizWMmELt3+28h/\n7yrT4Y2WM6vN2dLE3nkiFzgXEjOnrBlYfoNGGWP2WOCUynWr39lCpTfMDQcAA8ESAAwESwAwECwB\nwECwBAADwRIADARLADAQLAHAUJak9FCSavK4u/x/zklSNaqKzIUfQmnNyQUvrBxcMx/WWUjD6Xmm\nlwaTv8sa7eWcFt3xNMYh1F4urw1vQJ3X2T0TitmUIJfte99jY5ETZY33Q5EzMPJ20zAGK3KT0o03\nqvN+D70wue77vZgLfITwyRIADARLADAQLAHAQLAEAAPBEgAMBEsAMBAsAcBAsAQAQ1mS0tU9ObTA\n8VCRHn/i7AhnrDbup+kGEurjvq0e7SZtW+Ng1NVbNckc47hECefWrpsqbuXy/uyi6Yyn26diUruT\n/XDz963dJJ2V0oteVb7rN9YYuG9mZyNTq5rAe7Tb8Zw9EaUwPlkCgIFgCQAGgiUAGAiWAGAgWAKA\ngWAJAAaCJQAYCJYAYCBYAoChPNtKGMf9GTzpisvT71ZXoF/5s0mcFr1exc50C2dmRy9l3LHuas6Z\nMWTO4LHaLlwobweF4nZK6CfnORY+Q3Nx36fwxJnS7FdS7Pshf9yN9txtJQxxEZt5xN37WmS3+GQJ\nAAaCJQAYCJYAYCBYAoCBYAkABoIlABgIlgBgIFgCgKE820o4WeklzDJ2th9w82aDXe9zkrHbYHoS\nrrOFQ4+E3IRcrqsNJwk+sgbUTLS2ChWuK5nYHdlbF5QmsftGXf1PSo/jrs08rIkHkrvHSGqJyEpu\nD9eVS5yTUZwtWCavFvPN5SWvG2VCH/m6n7e5/ie499ZMntOnT2vGjBk6ePCgJKmxsVHf/va39fTT\nT+vpp5/W7373u6I6AQCDXeonyytXrmjjxo2aNGlS3vFly5Zp6tSpN61jADCYpH6yrKqq0r59+1RT\nU1OO/gDAoJQaLCsrKzV8+PAexw8ePKi5c+dq6dKlunTp0k3pHAAMFlHc252AhF27dmnUqFGaM2eO\nWlpaNHLkSE2YMEF79+7VJ598orVr1wb/9pML5/XvY8aWrNMAUG79uhuevH45bdo0rV+/vtfyO35x\noMexbc/Xa8WOps7H2Y70u2ySlLN2Znfu8PZ/4apXVtZr6aauvisuXQZWbPTLuxte+Phr65bpxxt2\ndpWz7oYbY+Xe4bX0rOu1tT/Wj198rauEfTfcKXRz74a/unapFr/4Sldr9lgN/N3wV1ct1+KXt3fV\nZdwNd1NNvLvh6XewowJvv52Nq7Rsy8vd2kt/n+5oeCH4u369yxctWqQzZ85IklpbWzV+/Pj+VAMA\nQ0bqJ8uTJ09q69atOnv2rCorK3XkyBHNmTNHS5Ys0YgRI1RdXa3NmzeXo68AMGBSg+XEiRP15ptv\n9jj+rW99y24kdFk0eTx2v1ZZCefphdyVvUMJ0sn+mpd9veaMvFmrvVz4S0Pym5S1Grfx2kQl/Boe\nutSSyyaSo82vzs5lDfdruPUMA18tc3nni9Wc9/XZOhfcBgMJ9dnkJAajHrc943ttZBSKQqvTdztc\nUVHcOcp0RwAwECwBwECwBAADwRIADARLADAQLAHAQLAEAAPBEgAMBEsAMJRnW4nQwg+J4/YcGKNg\n1pnBY68tULhgNjk9oIQzhuJeZt50clbH73Vbib7NOHKKu9t0OK9fHJhJksslpx6ZzTkzi+yTwVh0\nJND3bGIWjLu5gfVJxnlt5C1Sk8kEZvDkkltilKhTZjFnsY1Qke7nrbU9Si/4ZAkABoIlABgIlgBg\nIFgCgIFgCQAGgiUAGAiWAGAgWAKAoSxJ6aFc0OTxnJkwmss6Wc0lKdJrwbxtAoxk5djeBqFEW1T0\nsj9FNvk7K8HdKGOu2O8kr4fGIJmU7m0XITmddycMFLOtRHISg3sulEpo24XuQpMVOvKOl26GgjOe\nUSa9VCbwka/7KVLsuPPJEgAMBEsAMBAsAcBAsAQAA8ESAAwESwAwECwBwECwBAADwRIADGWawVM4\ncz7vuLnWfq6XmSl9qcvdWSG4ZH22azZJ1mgwMv8vWTN4jDJRXNHLnyf7a7RnjKc788gqFSiU7Uhs\nj+DuYxGnj3tcwhknIcnzxd+BI71kpohtOly5bHL2kXGul/AjWIUxUyu0dUjcx+1T0vDJEgAMBEsA\nMBAsAcBAsAQAA8ESAAwESwAwECwBwECwBABDWZLSc4Gk3+Tx2Ek2lxQZyc9OLmrOzdMNtJe/TUD6\n/5xcnE0tc6Oy9LoiZ6uEXpJ5c4m+54wk44yRGOxuCxLIH84T6nteG/b2G6XaN8PffqJgL/L6687A\nSD9nct7mDFZzUeB9mkxEj4y67FGyEuqNpPRcKCm92/GK4pLUrWDZ1NSkEydOqKOjQ/Pnz9d9992n\n+vp6ZbNZjR07Vtu2bVNVVVVRHQGAwSw1WB47dkwffvihmpubdfnyZT3xxBOaNGmS6urqNHPmTO3c\nuVOHDx9WXV1dOfoLAAMi9Tvfgw8+qFdffVWSdPvtt+vq1atqbW3V9OnTJUlTp05VS0vLze0lAAyw\nKO7D3qvNzc06fvy4fv/733cGyD//+c+qr6/XoUOHgn937vx53TF2bPG9BYABYt/geeedd3T48GHt\n379fjz32WOdxJ9Zu3f9Gj2M/aWjUkq1bOh9nv7xu9cPZN9y5eZMt4gbP3pfX6dlVG7qKGDd47H9J\nJbrBo8CqQ/u2vKB5jZs7Hw+VGzxvNK3UM/WbkqWs9qzbDe4KRv28wfPG1pV6piHZd/NmZib9Bo9z\nw8UadBW+wbP35bV6dtWLfWrPXnXI6bq1b3jPMv+1dpX+94sv5x0bNiz9df7JC6vD7aT+taT33ntP\nu3fv1r59+3Tbbbepurpa7e3tkqS2tjbV1NQ41QDAkJUaLD///HM1NTVpz549GjlypCRp8uTJOnLk\niCTp6NGjmjJlys3tJQAMsNSv4W+//bYuX76sJUuWdB7bsmWLVq9erebmZo0bN06PP/74Te0kAAy0\n1GA5e/ZszZ49u8fxAwcO2I1kAkmjyeMdxrU6yVs9Omdfz/JaTC9htGdeN5LSr1M57UW5jl4quNb5\nY4eGpffIWnHaHHOjrtAVvauJJG13NJ1LqaFk7B51ZYzJB4GX728dXc+qqtKboJDNhVe7T/QqtYT7\n/ELXwq8m7hNExqrrGfPVyRjviYzR92GBenLd+podNtzqV7AvRf01APyLIFgCgIFgCQAGgiUAGAiW\nAGAgWAKAgWAJAAaCJQAYCJYAYCjLthIdlYVjcvJ4h7lqTUdHermssaSQsXiRJCkKbHdxLXHcWeXI\nXXUo42xRYbRX0cuMqC+zXb+LK5wZQ+msWUwyZ96EVprJJNqwZhWZDZqzqzJGkxUVhV+cYRV9O18k\nKQ7UlV8ovYyzFYskxcFtJbLJB6lyxipVUvhlzi9jzGIKni/djrtv+lAzRf01APyLIFgCgIFgCQAG\ngiUAGAiWAGAgWAKAgWAJAAaCJQAYypKUHtrOMnk8krOEvpRRL9sl/F3W2a7TTKIOlYrzfnaSh71E\n3VzGqMvI5g3s5HHjd5WJ3hsJ/LGRtG3kRv+9oDHu2UB7ib6GEqi7M9OjrVIytlQIbWmSd9zeetfZ\nE8OoxdyDI/j0kt1whsoYpxvl0t/zOePciwKdynU7XuxmM3yyBAADwRIADARLADAQLAHAQLAEAAPB\nEgAMBEsAMBAsAcBQlqR0K7XbzBgt3ardXuJsqK64j33vZeHyPKGk5qTISbrvJfk7l/hdVKJ/lxmz\nHm/R7sBrk5ew72Vae8nr7gQFJ4G/cKJ1Mrk6MpO2rfPYeAHd+QKZwFLwubzj6bU5q/1LUofx/CqM\nMhnnParuz6Pv+GQJAAaCJQAYCJYAYCBYAoCBYAkABoIlABgIlgBgIFgCgIFgCQAGawZPU1OTTpw4\noY6ODs2fP1/vvvuuTp06pZEjR0qSnnnmGT366KPBv48Dsy3yjhtbJdz4I2P2ijGdpLdtF/ILhmaT\nJCtwK0tnrKJv7jYQriiq6PpdNudMP+r/dgo9qnKaCxTqSLwWGXvKkDF/xdzmIWO9ONnU4xlz2lTO\nmC3jdMneViIwzSxK9DcyGvTGScoY73mnrtAWMd2PF7utRGqwPHbsmD788EM1Nzfr8uXLeuKJJ/TN\nb35Ty5Yt09SpU4tsHgCGhtRg+eCDD+r++++XJN1+++26evWqstnQf08A+OeU+n2goqJC1dXVkqTD\nhw/r4YcfVkVFhQ4ePKi5c+dq6dKlunTp0k3vKAAMpCgOXSDq5p133tGePXu0f/9+nTx5UiNHjtSE\nCRO0d+9effLJJ1q7dm3wb//fhQsaN2ZMyToNAOVm3eB57733tHv3bv385z/XbbfdpkmTJnX+btq0\naVq/fn2vf7/lF//d49hrzy/Xj3ds73x8/cv0/cAlqSObXq7jenr8z5obXccFbvC8+dIGPb16XaKM\nUY/Vmnkx3iiUCdzgObhpneas3ND5OBu6gZXXXnrvzf+53lgVqOv/7nhJ331+dedj+waPs0CZe0PC\n2T+9wLj/n60b9L2GrvOlwuy7d4PH6JO7x3qBYr/ctEH/a2VX3yOjLvsGT0V6uYqK9L3FKwvUs2fV\nas1/+aX89qqGpdb1sxUNwd+lvmqff/65mpqatGfPns6734sWLdKZM2ckSa2trRo/fnxqJwBgKEv9\nZPn222/r8uXLWrJkSeexJ598UkuWLNGIESNUXV2tzZs339ROAsBASw2Ws2fP1uzZs3scf+KJJ25K\nhwBgMBo020pE5uL3GeOaSWBl//x6zLX2QznbycsyTo5xzrym51zNcq5r9nbdKHnJLHaueRlj5Y5n\n1ljaP5RQn7zG5c5hiEq1b4bM1ybQsYpE34eZ1/SyTgK/sw2Je8E80K38S4IlTEo3RjR07T2/R4Fk\n+m7HM+7eLsG+AABSESwBwECwBAADwRIADARLADAQLAHAQLAEAAPBEgAMZUlKD+UhJ4+HVmnu8TdG\n8rqRky53dfPQquvJxRBiq+/9X8ygZ03OQhrhPmWirpc9GxmLNeTS1y8185BVUcTCD3kLL5jLfzvF\nQknNPepyEsCdBOkKrz3nGWaMJxgbr7EUPveSi5ZYEyLMhUIiYyEN5/Nc6D3a/biz6EhxPQEAECwB\nwEGwBAADwRIADARLADAQLAHAQLAEAAPBEgAMBEsAMJRpW4lQ5nzXcXNChmTMlomMmRYZcxZFaEuF\nTKZrnpAzo8ZmbD9hzj0K/yoxc6LS+H/pPL/I3DbD2aMidC5UJrZFdbbDkLyxcl8/ZwZIaBuEisqu\nvldYM1esU8HqU2ibju5CZ0Ky785MNHumjFEsNqbjhUJC9+N2jAngkyUAGAiWAGAgWAKAgWAJAAaC\nJQAYCJYAYCBYAoCBYAkAhrIkpUeBkJw87i5FnzMSS52cXydxvbfKKod1DZ2Xj+1lxOZKlfTbSzXD\nhnVl+matzOcSlZGknJFlHKgrOebuPhaR0a848jYicU6ZTKBQ5bCu87vC3XahRJ9l7PkegeOZyq5x\nzziTJsyke6tjxuscaq77FiYZktIB4OYjWAKAgWAJAAaCJQAYCJYAYCBYAoCBYAkABoIlABjKkpSe\nCSSW5h03k4wrnARiJynWXdg7cHxYZaVRqkvO/L9kJcsbY5Xt5XcVVV19r3Cay5qD5fCWLi/oK1Vf\n6Xpg/psvorn+1RZYCX5YIqG+wsyOds6ZTJS+8ry7RHhowsewqmGdPzsr4jsTAW4UTC9izZkIvILd\nJ28Uu59BarC8evWqGhsbdfHiRV27dk0LFizQvffeq/r6emWzWY0dO1bbtm1TVVVVkV0BgMErNVj+\n9re/1cSJEzVv3jydPXtWP/zhD/XAAw+orq5OM2fO1M6dO3X48GHV1dWVo78AMCBSP+fPmjVL8+bN\nkySdO3dOtbW1am1t1fTp0yVJU6dOVUtLy83tJQAMMPua5VNPPaVPPvlEu3fv1g9+8IPOr92jR4/W\n+fPnb1oHAWAwiOLY3cNU+uCDD1RfX6/z58/r2LFjkqSPP/5YDQ0NOnToUPDvzl24oDvGjCm+twAw\nQFI/WZ48eVKjR4/WHXfcoQkTJiibzeqWW25Re3u7hg8frra2NtXU1PRax/Y3f9Hj2I6lz+v5V3Z0\nPr523birJ/OOVpFLmKUVe71+uRY2be9TZYPlbvjuFc/ruW1d4241Nwjuhv/sheX6z82JMR9Cd8N/\n1rhC/7llW+fjoXQ3/KcrnteCxPkyVO6Gv76iXgu3NeUdc5aBfO355cHfpf718ePHtX//fknShQsX\ndOXKFU2ePFlHjhyRJB09elRTpkxJ7QQADGWpnyyfeuoprVq1SnV1dWpvb9fatWs1ceJENTQ0qLm5\nWePGjdPjjz9ejr4CwIBJDZbDhw/Xjh07ehw/cODATekQAAxG5ZnBkyncTPL4sMrSXbN0tl2Izes4\nIVWVXbMaYuP6WWzOH3CuWcbG88vE4Tk8w4Yl9/NIn0yQ6Uh/bdx5sznrenLhMaj6StcMHmtrDUlx\nH65IOrWlyajwWA3/SuJ8cftuXPurNLbp8Eeg8Ks4vLLrHIkCM5Ty2rNfG+d9mt5eFJh6NCwanve4\no+JLq18hzA0HAAPBEgAMBEsAMBAsAcBAsAQAA8ESAAwESwAwECwBwNCnVYcA4F8VnywBwECwBAAD\nwRIADARLADAQLAHAQLAEAENZ1rPsbtOmTXr//fcVRZFWrlyp+++/fyC60Setra1avHixxo8fL0m6\n5557tGbNmgHuVbrTp09rwYIF+v73v685c+bo3Llzqq+vVzab1dixY7Vt27bOnToHk+79bmxs1KlT\npzRy5EhJ0jPPPKNHH310YDsZ0NTUpBMnTqijo0Pz58/XfffdNyTGXOrZ93fffXfQj/vVq1fV2Nio\nixcv6tq1a1qwYIHuvffe0o95XGatra3xs88+G8dxHH/00Ufxd7/73XJ3oV+OHTsWL1q0aKC70Sd/\n+9vf4jlz5sSrV6+O33zzzTge/K2cAAADsUlEQVSO47ixsTF+++234ziO4x07dsS//OUvB7KLBRXq\nd0NDQ/zuu+8OcM/StbS0xD/60Y/iOI7jS5cuxY888siQGPM4Ltz3oTDuv/71r+O9e/fGcRzHf/nL\nX+LHHnvspox52b+Gt7S0aMaMGZKku+++W5999pm++OKLcnfjX0JVVZX27duXt/tma2urpk+fLkma\nOnWqWlpaBqp7QYX6PVQ8+OCDevXVVyVJt99+u65evTokxlwq3PdsNrzi/mAxa9YszZs3T5J07tw5\n1dbW3pQxL3uwvHDhgkaNGtX5+Ktf/arOnz9f7m70y0cffaTnnntO3/ve9/SHP/xhoLuTqrKyUsOH\n5y+tf/Xq1c6vI6NHjx6UY1+o35J08OBBzZ07V0uXLtWlS5cGoGfpKioqVF1dLUk6fPiwHn744SEx\n5lLhvldUVAyJcZdubK64fPlyrVy58qaM+YBcs0yKh8hsy//4j//QwoULNXPmTJ05c0Zz587V0aNH\nB+21J8dQGXtJ+s53vqORI0dqwoQJ2rt3r15//XWtXbt2oLsV9M477+jw4cPav3+/Hnvssc7jQ2HM\nk30/efLkkBn3Q4cO6YMPPtCKFSvyxrlUY172T5Y1NTW6cOFC5+NPP/1UY8eOLXc3+qy2tlazZs1S\nFEW68847NWbMGLW1tQ10t/qsurpa7e3tkqS2trYh81V30qRJmjBhgiRp2rRpOn369AD3KOy9997T\n7t27tW/fPt12221Dasy7930ojPvJkyd17tw5SdKECROUzWZ1yy23lHzMyx4sH3roIR05ckSSdOrU\nKdXU1OjWW28tdzf67K233tIbb7whSTp//rwuXryo2traAe5V302ePLlz/I8ePaopU6YMcI88ixYt\n0pkzZyTduO76j6yEwebzzz9XU1OT9uzZ03kHeaiMeaG+D4VxP378uPbv3y/pxmW+K1eu3JQxH5BV\nh7Zv367jx48riiKtW7dO9957b7m70GdffPGFli9frr/+9a+6fv26Fi5cqEceeWSgu9WrkydPauvW\nrTp79qwqKytVW1ur7du3q7GxUdeuXdO4ceO0efNmDRs2LL2yMirU7zlz5mjv3r0aMWKEqqurtXnz\nZo0ePXqgu9pDc3Ozdu3apbvuuqvz2JYtW7R69epBPeZS4b4/+eSTOnjw4KAe9/b2dq1atUrnzp1T\ne3u7Fi5cqIkTJ6qhoaGkY84SbQBgYAYPABgIlgBgIFgCgIFgCQAGgiUAGAiWAGAgWAKAgWAJAIb/\nD5PLt1Z4Hyd3AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "WqaMt-F_1OS0",
        "colab_type": "code",
        "outputId": "d7089873-ac9c-4237-a3dc-74d1e14d6ca8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(target)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f1c0586aa90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "q21AZNdnKy4o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class double_conv(nn.Module):\n",
        "    '''(conv => BN => ReLU) * 2'''\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(double_conv, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class inconv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(inconv, self).__init__()\n",
        "        self.conv = double_conv(in_ch, out_ch)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class down(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(down, self).__init__()\n",
        "        self.mpconv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            double_conv(in_ch, out_ch)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.mpconv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class up(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, bilinear=True):\n",
        "        super(up, self).__init__()\n",
        "\n",
        "        #  would be a nice idea if the upsampling could be learned too,\n",
        "        #  but my machine do not have enough memory to handle all those weights\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_ch//2, in_ch//2, 2, stride=2)\n",
        "\n",
        "        self.conv = double_conv(in_ch, out_ch)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        \n",
        "        # input is CHW\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        x1 = F.pad(x1, (diffX // 2, diffX - diffX//2,\n",
        "                        diffY // 2, diffY - diffY//2))\n",
        "        \n",
        "        # for padding issues, see \n",
        "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
        "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
        "\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class outconv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(outconv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_ch, out_ch, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X3tV2m-hLzzz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes):\n",
        "        super(UNet, self).__init__()\n",
        "        self.inc = inconv(n_channels, 64)\n",
        "        self.down1 = down(64, 128)\n",
        "        self.down2 = down(128, 256)\n",
        "        self.down3 = down(256, 512)\n",
        "        self.down4 = down(512, 512)\n",
        "        self.up1 = up(1024, 256)\n",
        "        self.up2 = up(512, 128)\n",
        "        self.up3 = up(256, 64)\n",
        "        self.up4 = up(128, 64)\n",
        "        self.outc = outconv(64, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        x = self.outc(x)\n",
        "        return F.sigmoid(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AMM1BxZW4FDC",
        "colab_type": "code",
        "outputId": "7779fefd-1ef0-4c51-ac1a-9cd4e356c359",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cRaxlVwE4RHJ",
        "colab_type": "code",
        "outputId": "92f0c6af-30bd-41fd-ea8b-d33b3f63eedf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1680
        }
      },
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = UNet(1,3).to(device)\n",
        "summary(model, (1, 32, 32))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]             640\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "       double_conv-7           [-1, 64, 32, 32]               0\n",
            "            inconv-8           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-9           [-1, 64, 16, 16]               0\n",
            "           Conv2d-10          [-1, 128, 16, 16]          73,856\n",
            "      BatchNorm2d-11          [-1, 128, 16, 16]             256\n",
            "             ReLU-12          [-1, 128, 16, 16]               0\n",
            "           Conv2d-13          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-14          [-1, 128, 16, 16]             256\n",
            "             ReLU-15          [-1, 128, 16, 16]               0\n",
            "      double_conv-16          [-1, 128, 16, 16]               0\n",
            "             down-17          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-18            [-1, 128, 8, 8]               0\n",
            "           Conv2d-19            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-20            [-1, 256, 8, 8]             512\n",
            "             ReLU-21            [-1, 256, 8, 8]               0\n",
            "           Conv2d-22            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-23            [-1, 256, 8, 8]             512\n",
            "             ReLU-24            [-1, 256, 8, 8]               0\n",
            "      double_conv-25            [-1, 256, 8, 8]               0\n",
            "             down-26            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-27            [-1, 256, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "      double_conv-34            [-1, 512, 4, 4]               0\n",
            "             down-35            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-36            [-1, 512, 2, 2]               0\n",
            "           Conv2d-37            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-38            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-39            [-1, 512, 2, 2]               0\n",
            "           Conv2d-40            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-41            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-42            [-1, 512, 2, 2]               0\n",
            "      double_conv-43            [-1, 512, 2, 2]               0\n",
            "             down-44            [-1, 512, 2, 2]               0\n",
            "         Upsample-45            [-1, 512, 4, 4]               0\n",
            "           Conv2d-46            [-1, 256, 4, 4]       2,359,552\n",
            "      BatchNorm2d-47            [-1, 256, 4, 4]             512\n",
            "             ReLU-48            [-1, 256, 4, 4]               0\n",
            "           Conv2d-49            [-1, 256, 4, 4]         590,080\n",
            "      BatchNorm2d-50            [-1, 256, 4, 4]             512\n",
            "             ReLU-51            [-1, 256, 4, 4]               0\n",
            "      double_conv-52            [-1, 256, 4, 4]               0\n",
            "               up-53            [-1, 256, 4, 4]               0\n",
            "         Upsample-54            [-1, 256, 8, 8]               0\n",
            "           Conv2d-55            [-1, 128, 8, 8]         589,952\n",
            "      BatchNorm2d-56            [-1, 128, 8, 8]             256\n",
            "             ReLU-57            [-1, 128, 8, 8]               0\n",
            "           Conv2d-58            [-1, 128, 8, 8]         147,584\n",
            "      BatchNorm2d-59            [-1, 128, 8, 8]             256\n",
            "             ReLU-60            [-1, 128, 8, 8]               0\n",
            "      double_conv-61            [-1, 128, 8, 8]               0\n",
            "               up-62            [-1, 128, 8, 8]               0\n",
            "         Upsample-63          [-1, 128, 16, 16]               0\n",
            "           Conv2d-64           [-1, 64, 16, 16]         147,520\n",
            "      BatchNorm2d-65           [-1, 64, 16, 16]             128\n",
            "             ReLU-66           [-1, 64, 16, 16]               0\n",
            "           Conv2d-67           [-1, 64, 16, 16]          36,928\n",
            "      BatchNorm2d-68           [-1, 64, 16, 16]             128\n",
            "             ReLU-69           [-1, 64, 16, 16]               0\n",
            "      double_conv-70           [-1, 64, 16, 16]               0\n",
            "               up-71           [-1, 64, 16, 16]               0\n",
            "         Upsample-72           [-1, 64, 32, 32]               0\n",
            "           Conv2d-73           [-1, 64, 32, 32]          73,792\n",
            "      BatchNorm2d-74           [-1, 64, 32, 32]             128\n",
            "             ReLU-75           [-1, 64, 32, 32]               0\n",
            "           Conv2d-76           [-1, 64, 32, 32]          36,928\n",
            "      BatchNorm2d-77           [-1, 64, 32, 32]             128\n",
            "             ReLU-78           [-1, 64, 32, 32]               0\n",
            "      double_conv-79           [-1, 64, 32, 32]               0\n",
            "               up-80           [-1, 64, 32, 32]               0\n",
            "           Conv2d-81            [-1, 3, 32, 32]             195\n",
            "          outconv-82            [-1, 3, 32, 32]               0\n",
            "================================================================\n",
            "Total params: 13,394,307\n",
            "Trainable params: 13,394,307\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 14.59\n",
            "Params size (MB): 51.10\n",
            "Estimated Total Size (MB): 65.69\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}